{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Why should you work with this type of dataset\nIf you work on this type of dataset, you can implmenet similar solutions in any IoT related project in your organization or personal project. \n\nThis dataset can help you to learn:\n    - how to approach sensors data\n    - how to find anomaly which can help you to know when device is going to break\n    - It do have timeseries angle, so could look for that too. ","metadata":{}},{"cell_type":"markdown","source":"# Step 1. \n - Have a quick look on the dataset, which is very much needed to build the thought process around the data\n - Reread problem statement multiple times and try to understand how to correlate the dataset and problem. \n - Plot the visualization \n \n Our problem statment: Look for the correlation of sensors which leads to device breakdown\n","metadata":{}},{"cell_type":"markdown","source":"\n1. Quick Checklist for this dataset\n*     timeseries forecasting problem \n*     machine status - 3 convert that into label encoding \n*     all numerical values\n*     anomaly detection \n*     labelled data - supervised learning , classification \n*     look for correlation matrix \n*     look for skewness in the data \n*     check imbalance data if any ","metadata":{}},{"cell_type":"code","source":"# load the dataset \nimport pandas as pd\nimport numpy as np\n\ndf = pd.read_csv('../input/pumpsensor/sensor.csv')\ndf.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T14:54:48.160879Z","iopub.execute_input":"2022-06-16T14:54:48.161460Z","iopub.status.idle":"2022-06-16T14:54:51.228572Z","shell.execute_reply.started":"2022-06-16T14:54:48.161394Z","shell.execute_reply":"2022-06-16T14:54:51.227917Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"df.tail()\n\n# 01-Apr-2018 to 31-Aug-2018 \n# apr, may, jun, jul, aug - 5 months every min data is collected ","metadata":{"execution":{"iopub.status.busy":"2022-06-16T14:54:51.230161Z","iopub.execute_input":"2022-06-16T14:54:51.230717Z","iopub.status.idle":"2022-06-16T14:54:51.258156Z","shell.execute_reply.started":"2022-06-16T14:54:51.230676Z","shell.execute_reply":"2022-06-16T14:54:51.256836Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# \"Unnamed\" column removed (deleted).","metadata":{}},{"cell_type":"code","source":"del df['Unnamed: 0']","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-16T14:54:51.260157Z","iopub.execute_input":"2022-06-16T14:54:51.260629Z","iopub.status.idle":"2022-06-16T14:54:51.269217Z","shell.execute_reply.started":"2022-06-16T14:54:51.260555Z","shell.execute_reply":"2022-06-16T14:54:51.268555Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# change timestamp column into the index column\ndf['index'] = pd.to_datetime(df['timestamp'])\ndf.index = df['index']","metadata":{"execution":{"iopub.status.busy":"2022-06-16T14:54:51.270887Z","iopub.execute_input":"2022-06-16T14:54:51.271481Z","iopub.status.idle":"2022-06-16T14:54:51.381428Z","shell.execute_reply.started":"2022-06-16T14:54:51.271424Z","shell.execute_reply":"2022-06-16T14:54:51.380169Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"# Again, looking at the row titles","metadata":{}},{"cell_type":"code","source":"df.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T14:54:51.384996Z","iopub.execute_input":"2022-06-16T14:54:51.385578Z","iopub.status.idle":"2022-06-16T14:54:51.415240Z","shell.execute_reply.started":"2022-06-16T14:54:51.385514Z","shell.execute_reply":"2022-06-16T14:54:51.414196Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# delete the colunmns. Now, the timestamp is in the index column\ndel df['index']\ndel df['timestamp']","metadata":{"execution":{"iopub.status.busy":"2022-06-16T14:54:51.418252Z","iopub.execute_input":"2022-06-16T14:54:51.418868Z","iopub.status.idle":"2022-06-16T14:54:51.432014Z","shell.execute_reply.started":"2022-06-16T14:54:51.418821Z","shell.execute_reply":"2022-06-16T14:54:51.430799Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"df.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T14:54:51.433677Z","iopub.execute_input":"2022-06-16T14:54:51.434468Z","iopub.status.idle":"2022-06-16T14:54:51.461738Z","shell.execute_reply.started":"2022-06-16T14:54:51.434127Z","shell.execute_reply":"2022-06-16T14:54:51.460754Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"df['sensor_15'].nunique() # no unique - complete zero\n# drop the column \ndf.drop(['sensor_15'], axis=1, inplace = True)\ndf.shape","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2022-06-16T14:54:51.463338Z","iopub.execute_input":"2022-06-16T14:54:51.463720Z","iopub.status.idle":"2022-06-16T14:54:51.497098Z","shell.execute_reply.started":"2022-06-16T14:54:51.463636Z","shell.execute_reply":"2022-06-16T14:54:51.496198Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T14:54:51.498505Z","iopub.execute_input":"2022-06-16T14:54:51.499021Z","iopub.status.idle":"2022-06-16T14:54:51.724959Z","shell.execute_reply.started":"2022-06-16T14:54:51.498968Z","shell.execute_reply":"2022-06-16T14:54:51.724247Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# machine status - no null \n# we will drop na in whole dataframe \ndf['sensor_00'].isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T14:54:51.726128Z","iopub.execute_input":"2022-06-16T14:54:51.726621Z","iopub.status.idle":"2022-06-16T14:54:51.736154Z","shell.execute_reply.started":"2022-06-16T14:54:51.726564Z","shell.execute_reply":"2022-06-16T14:54:51.735256Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"# Request number of counts for 'NORMAL', 'BROKEN', 'RECOVERING' ","metadata":{}},{"cell_type":"code","source":"# machine status\ndf['machine_status'].unique()#'NORMAL', 'BROKEN', 'RECOVERING' \ndf['machine_status'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T14:54:51.738169Z","iopub.execute_input":"2022-06-16T14:54:51.738605Z","iopub.status.idle":"2022-06-16T14:54:51.825188Z","shell.execute_reply.started":"2022-06-16T14:54:51.738415Z","shell.execute_reply":"2022-06-16T14:54:51.824465Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# draw a countplot for machine status \nimport seaborn as sns\nsns.countplot(y = df['machine_status'])","metadata":{"execution":{"iopub.status.busy":"2022-06-16T14:54:51.826508Z","iopub.execute_input":"2022-06-16T14:54:51.826791Z","iopub.status.idle":"2022-06-16T14:54:52.060394Z","shell.execute_reply.started":"2022-06-16T14:54:51.826740Z","shell.execute_reply":"2022-06-16T14:54:52.059527Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"** Steps to discover the metrics that identify device failures, \n* it is highly imbalanced data  and undersampling can't help here \n* next, is an experiment with SMOTE or oversampling ","metadata":{}},{"cell_type":"code","source":"# apply label encoder to encode the machine status\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndf['machine_status'] = le.fit_transform(df['machine_status'])\ndf['machine_status'].value_counts()\n\n# 1 - normal \n# 2 - recovering \n# 0 - broken","metadata":{"execution":{"iopub.status.busy":"2022-06-16T14:54:52.062089Z","iopub.execute_input":"2022-06-16T14:54:52.062356Z","iopub.status.idle":"2022-06-16T14:54:52.153582Z","shell.execute_reply.started":"2022-06-16T14:54:52.062310Z","shell.execute_reply":"2022-06-16T14:54:52.152782Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"#  look on complete data frame when device is broken\ndf_broken = df[df.machine_status ==0]\ndf_broken\n\n# there is no nan value corellation for broken device \n#","metadata":{"execution":{"iopub.status.busy":"2022-06-16T14:54:52.154870Z","iopub.execute_input":"2022-06-16T14:54:52.155237Z","iopub.status.idle":"2022-06-16T14:54:52.186525Z","shell.execute_reply.started":"2022-06-16T14:54:52.155146Z","shell.execute_reply":"2022-06-16T14:54:52.185718Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt \nplt.plot(df['sensor_02'])","metadata":{"execution":{"iopub.status.busy":"2022-06-16T14:54:52.188089Z","iopub.execute_input":"2022-06-16T14:54:52.188358Z","iopub.status.idle":"2022-06-16T14:54:52.436208Z","shell.execute_reply.started":"2022-06-16T14:54:52.188308Z","shell.execute_reply":"2022-06-16T14:54:52.435392Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# imputation for null values \ndf['sensor_04'].hist()\n# data is skewed so we need to use median value to fill the data","metadata":{"execution":{"iopub.status.busy":"2022-06-16T14:54:52.437203Z","iopub.execute_input":"2022-06-16T14:54:52.437470Z","iopub.status.idle":"2022-06-16T14:54:52.666510Z","shell.execute_reply.started":"2022-06-16T14:54:52.437432Z","shell.execute_reply":"2022-06-16T14:54:52.665741Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# let us figureout NaN values \ndf['sensor_00'].isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T14:54:52.667864Z","iopub.execute_input":"2022-06-16T14:54:52.668420Z","iopub.status.idle":"2022-06-16T14:54:52.679349Z","shell.execute_reply.started":"2022-06-16T14:54:52.668363Z","shell.execute_reply":"2022-06-16T14:54:52.678305Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"df['sensor_50'].isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T14:54:52.681023Z","iopub.execute_input":"2022-06-16T14:54:52.681539Z","iopub.status.idle":"2022-06-16T14:54:52.691333Z","shell.execute_reply.started":"2022-06-16T14:54:52.681483Z","shell.execute_reply":"2022-06-16T14:54:52.690301Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# used ffill method to fill the missing values\ndf = df.fillna(method='ffill')","metadata":{"execution":{"iopub.status.busy":"2022-06-16T14:54:52.692942Z","iopub.execute_input":"2022-06-16T14:54:52.694789Z","iopub.status.idle":"2022-06-16T14:54:52.766429Z","shell.execute_reply.started":"2022-06-16T14:54:52.693455Z","shell.execute_reply":"2022-06-16T14:54:52.765499Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"X = df.drop(['machine_status'], axis=1)\nX.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-16T14:54:52.767941Z","iopub.execute_input":"2022-06-16T14:54:52.768231Z","iopub.status.idle":"2022-06-16T14:54:52.855770Z","shell.execute_reply.started":"2022-06-16T14:54:52.768178Z","shell.execute_reply":"2022-06-16T14:54:52.855007Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y = df['machine_status']\nY.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-16T14:54:52.857349Z","iopub.execute_input":"2022-06-16T14:54:52.857632Z","iopub.status.idle":"2022-06-16T14:54:52.870598Z","shell.execute_reply.started":"2022-06-16T14:54:52.857579Z","shell.execute_reply":"2022-06-16T14:54:52.869770Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"# apply the logistic regression \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nX_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.30, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T14:54:52.871906Z","iopub.execute_input":"2022-06-16T14:54:52.872356Z","iopub.status.idle":"2022-06-16T14:54:53.030042Z","shell.execute_reply.started":"2022-06-16T14:54:52.872186Z","shell.execute_reply":"2022-06-16T14:54:53.029157Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# apply \nlogit = LogisticRegression()\nmodel = logit.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T14:54:53.031400Z","iopub.execute_input":"2022-06-16T14:54:53.031647Z","iopub.status.idle":"2022-06-16T14:57:01.172136Z","shell.execute_reply.started":"2022-06-16T14:54:53.031613Z","shell.execute_reply":"2022-06-16T14:57:01.171217Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# predict\ny_pred = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T14:57:01.173385Z","iopub.execute_input":"2022-06-16T14:57:01.173666Z","iopub.status.idle":"2022-06-16T14:57:01.189188Z","shell.execute_reply.started":"2022-06-16T14:57:01.173610Z","shell.execute_reply":"2022-06-16T14:57:01.188138Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# evaluate the model\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\ncm = pd.crosstab(y_test,y_pred, rownames=['True'], colnames=['Predicted'], margins=True)\ncm","metadata":{"execution":{"iopub.status.busy":"2022-06-16T14:57:01.190512Z","iopub.execute_input":"2022-06-16T14:57:01.190963Z","iopub.status.idle":"2022-06-16T14:57:01.260585Z","shell.execute_reply.started":"2022-06-16T14:57:01.190764Z","shell.execute_reply":"2022-06-16T14:57:01.259799Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"# accuracy is not a good metrics for Anomaly detection and imbalanced dataset\naccuracy = accuracy_score(y_test, y_pred)\naccuracy","metadata":{"execution":{"iopub.status.busy":"2022-06-16T14:57:01.261939Z","iopub.execute_input":"2022-06-16T14:57:01.262205Z","iopub.status.idle":"2022-06-16T14:57:01.270197Z","shell.execute_reply.started":"2022-06-16T14:57:01.262156Z","shell.execute_reply":"2022-06-16T14:57:01.269323Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# Classification Report\ncr = classification_report(y_pred, y_test)\nprint(cr)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T14:57:01.271603Z","iopub.execute_input":"2022-06-16T14:57:01.272028Z","iopub.status.idle":"2022-06-16T14:57:01.349968Z","shell.execute_reply.started":"2022-06-16T14:57:01.271971Z","shell.execute_reply":"2022-06-16T14:57:01.349348Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"# these reports are not good \nwe will use Isolation forest and oneSVM for modelling \nxgboosting feature_importance and PCA for dimension reduction \nbefore that we will divide this dataset into 2 problems\n machine status - normal + broken, normal + recovery, recovery+ broken ","metadata":{}},{"cell_type":"code","source":"df.shape # look on the shape of the dataset","metadata":{"execution":{"iopub.status.busy":"2022-06-16T14:57:01.351114Z","iopub.execute_input":"2022-06-16T14:57:01.351517Z","iopub.status.idle":"2022-06-16T14:57:01.356511Z","shell.execute_reply.started":"2022-06-16T14:57:01.351465Z","shell.execute_reply":"2022-06-16T14:57:01.355890Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":" machine status - normal + broken","metadata":{}},{"cell_type":"code","source":"df1 = df.copy()\ndf1 = df[(df1.machine_status ==1) | (df1.machine_status ==0)]\ndf1.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-16T14:57:01.357582Z","iopub.execute_input":"2022-06-16T14:57:01.357998Z","iopub.status.idle":"2022-06-16T14:57:01.445637Z","shell.execute_reply.started":"2022-06-16T14:57:01.357957Z","shell.execute_reply":"2022-06-16T14:57:01.444705Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}
